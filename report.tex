\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\newcommand{\del}{\nabla}
\begin{document}

\title{Cool Kids Boltzmann Machine}
\author{Hart Goldman, Howon Lee, Ian Tenney}
\maketitle

\section{Introduction}
Boltzmann machines are a thing. But they are slow. Sparsifying them makes them not crap.

Using networks of cool kids (or models of networks of cool kids) means that we also gain resilience against random attack, which sounds for defs like a cool kids thing. This is also probably where we bloviate about the interpolation between bias-y nodes and specific-y nodes in the power law distribution of edges

Taking advantage of this sparsification to make learning a lot faster, we see if we can get a language model which is also cool kids.

Looking for scale-freedom of the representation coolness sounds also appropriate to mention, and yadda yadda Zipf's statistical law. RG RG RG.

The most off-the-wall random bullshit: Minsky's Society of Mind, Kronecker graphs are actually designed to model society connectivity (radical inequality in indegree, outdegree: well, this B Obama guy has higher indegree than you for the is-known-of relation, doesn't he?).

\end{document}

